{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 16:54:10.470803: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/cero/anaconda3/envs/NPL/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c25e8a41de8c405a8d3069d2800042ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3400c43ec5404bd59968b864eb3580c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5044166937545579071ebc471841510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa98887a8031415486d6feb4e879899e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/480k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a9b5c7cb464203bc1fa1a2ef230b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3735235129d84a33b838da2b83564c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tf_model.h5:   0%|          | 0.00/537M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x144e8e8e0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x144e8e8e0> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "1/1 [==============================] - 64s 64s/step - loss: 0.6931 - accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.6931 - accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 1s 875ms/step - loss: 0.6931 - accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 1s 880ms/step - loss: 0.3466 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 6.3224 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 1s 869ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 1s 874ms/step - loss: 0.6931 - accuracy: 0.5000\n",
      "1/1 [==============================] - 8s 8s/step\n",
      "Epoch 1/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step - accuracy: 0.5000 - loss: 0.6918\n",
      "Epoch 2/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.6765\n",
      "Epoch 3/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.6609\n",
      "Epoch 4/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.6440\n",
      "Epoch 5/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 1.0000 - loss: 0.6248\n",
      "Epoch 6/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.6025\n",
      "Epoch 7/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.5759\n",
      "Epoch 8/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.5434\n",
      "Epoch 9/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 1.0000 - loss: 0.5028\n",
      "Epoch 10/10\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 1.0000 - loss: 0.4506\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194ms/step\n",
      "Predicciones de BERT (probabilidades):\n",
      "[[0.06752755 0.93247247]\n",
      " [0.06869487 0.9313051 ]]\n",
      "\n",
      "Predicciones de LSTM:\n",
      "[[0.31904718]\n",
      " [0.315509  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "\n",
    "# Datos de ejemplo (simulados)\n",
    "conversations = [\n",
    "    \"El cliente expresó claramente sus preocupaciones y el asesor pudo ofrecer soluciones efectivas.\",\n",
    "    \"La conversación fue confusa y el asesor no pudo ayudar al cliente de manera satisfactoria.\"\n",
    "]\n",
    "labels = [1, 0]  # Etiquetas de calidad de la conversación (1 para alta calidad, 0 para baja calidad)\n",
    "\n",
    "# Tokenización y padding para BERT\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=2)\n",
    "\n",
    "encoded_inputs = tokenizer(conversations, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "input_ids = encoded_inputs[\"input_ids\"]\n",
    "\n",
    "# Convertir etiquetas a tensores de TensorFlow\n",
    "labels_tensor = tf.convert_to_tensor(labels)\n",
    "\n",
    "# Modelo BER\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\", num_labels=2)\n",
    "bert_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenamiento del modelo BERT (usando los mismos datos simulados para simplicidad)\n",
    "bert_model.fit(input_ids, labels_tensor, epochs=10, batch_size=8)\n",
    "\n",
    "# Predicciones de BERT después del entrenamiento\n",
    "bert_predictions = bert_model.predict(input_ids).logits\n",
    "bert_predictions_prob = tf.nn.softmax(bert_predictions, axis=1).numpy()\n",
    "\n",
    "# Modelo LSTM\n",
    "vocab_size = 10000  # Tamaño del vocabulario\n",
    "embedding_dim = 100  # Dimensión de los vectores de embedding\n",
    "max_len = 50  # Longitud máxima de la secuencia\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim))\n",
    "lstm_model.add(LSTM(units=100))\n",
    "lstm_model.add(Dense(1, activation='sigmoid'))\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Datos de ejemplo para LSTM (simulados)\n",
    "X_train = np.random.randint(vocab_size, size=(len(conversations), max_len))\n",
    "y_train = np.random.randint(2, size=len(conversations))\n",
    "\n",
    "# Entrenar modelo LSTM\n",
    "lstm_model.fit(X_train, y_train, epochs=10, batch_size=8)\n",
    "\n",
    "# Obtener predicciones del modelo LSTM\n",
    "lstm_predictions = lstm_model.predict(X_train)\n",
    "\n",
    "# Salida final\n",
    "print(\"Predicciones de BERT (probabilidades):\")\n",
    "print(bert_predictions_prob)\n",
    "print(\"\\nPredicciones de LSTM:\")\n",
    "print(lstm_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "The following encoder weights were not tied to the decoder ['bert/pooler']\n",
      "No sentence-transformers model found with name dccuchile/bert-base-spanish-wwm-cased. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversación 1:\n",
      "El cliente expresó claramente sus preocupaciones sobre el rendimiento del producto y el asesor pudo ofrecer soluciones efectivas. El cliente se mostró satisfecho con la atención recibida y elogió la rapidez de la respuesta.\n",
      "\n",
      "\n",
      "Resumen: El cliente expresó bien sus preocupaciones sobre el rendimiento del producto y el asesor pudo ofrecer soluciones efectivas\n",
      "Palabras clave: [('cliente expresó', 0.7601), ('del producto', 0.7481), ('cliente se', 0.7421), ('el cliente', 0.7389), ('sobre el', 0.7388)]\n",
      "Entidades nombradas: [('El cliente', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 2:\n",
      "La conversación fue confusa y el asesor no pudo ayudar al cliente de manera satisfactoria. El cliente quedó insatisfecho con la falta de soluciones ofrecidas y mencionó que considerará cambiar de proveedor.\n",
      "\n",
      "\n",
      "Resumen: La conversación fue confusa y el asesor no pudo ayudar al cliente de manera satisfactoria. El cliente quedó insatisfecho con la falta de soluciones ofrecidas\n",
      "Palabras clave: [('quedó insatisfecho', 0.8322), ('fue confusa', 0.7944), ('insatisfecho la', 0.7903), ('soluciones ofrecidas', 0.7879), ('ofrecidas mencionó', 0.7727)]\n",
      "Entidades nombradas: [('El cliente', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 3:\n",
      "El asesor mostró empatía y comprensión hacia las necesidades del cliente, ofreciendo varias opciones de solución y explicando cada una en detalle. El cliente valoró la paciencia y el conocimiento del asesor.\n",
      "\n",
      "\n",
      "Resumen: El asesor mostró empatía y comprensión hacia las necesidades del cliente, ofreciendo distintas opciones de solución y explicando cada una en detalle cada una\n",
      "Palabras clave: [('explicando cada', 0.7955), ('mostró empatía', 0.7841), ('valoró la', 0.7794), ('cliente valoró', 0.777), ('solución explicando', 0.7763)]\n",
      "Entidades nombradas: [('El cliente', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 4:\n",
      "El cliente mencionó problemas recurrentes con el servicio, y aunque el asesor intentó ayudar, no se logró resolver la situación durante la llamada. El cliente expresó frustración y solicitó hablar con un supervisor.\n",
      "\n",
      "\n",
      "Resumen: El cliente expresó frustración y pidió hablar con un supervisor supervisor, no se logró resolver la situación durante la llamada\n",
      "Palabras clave: [('mencionó problemas', 0.7711), ('cliente expresó', 0.7657), ('frustración solicitó', 0.764), ('problemas recurrentes', 0.763), ('expresó frustración', 0.7599)]\n",
      "Entidades nombradas: [('El cliente', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 5:\n",
      "El cliente estaba molesto por la falta de comunicación sobre el estado de su pedido. El asesor se disculpó y ofreció un descuento en la próxima compra como compensación. El cliente aceptó la oferta y agradeció la solución rápida.\n",
      "\n",
      "\n",
      "Resumen: El cliente se disculpó y ofreció descuento en la próxima compra como compensación. El cliente aceptó la oferta y agradeció la solución rápida\n",
      "Palabras clave: [('se disculpó', 0.8023), ('disculpó ofreció', 0.783), ('su pedido', 0.7777), ('cliente aceptó', 0.767), ('comunicación sobre', 0.7647)]\n",
      "Entidades nombradas: [('comunicación', 'LOC'), ('El asesor se disculpó', 'MISC'), ('El cliente', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 6:\n",
      "El asesor proporcionó información detallada sobre las características del nuevo producto, respondiendo a todas las preguntas del cliente. El cliente expresó su interés en realizar una compra y pidió más detalles sobre el proceso de envío.\n",
      "\n",
      "\n",
      "Resumen: El cliente expresó su interés en realizar una compra y pidió más detalles sobre el proceso de envío de productos\n",
      "Palabras clave: [('más detalles', 0.7658), ('sobre las', 0.757), ('proporcionó información', 0.7558), ('cliente expresó', 0.7553), ('información detallada', 0.7536)]\n",
      "Entidades nombradas: [('El cliente', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 7:\n",
      "La llamada fue muy positiva, con el asesor y el cliente discutiendo posibles mejoras al servicio. El cliente ofreció sugerencias constructivas y el asesor se comprometió a transmitirlas al equipo correspondiente.\n",
      "\n",
      "\n",
      "Resumen: La llamada fue muy positiva, con el asesor y el cliente discutiendo posibles mejoras al servicio\n",
      "Palabras clave: [('sugerencias constructivas', 0.7753), ('transmitirlas al', 0.7633), ('constructivas el', 0.7514), ('ofreció sugerencias', 0.7496), ('cliente ofreció', 0.7487)]\n",
      "Entidades nombradas: [('El cliente ofreció sugerencias constructivas', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 8:\n",
      "El cliente estaba insatisfecho con la calidad del producto recibido y solicitó un reembolso. El asesor procesó la solicitud de reembolso de inmediato y explicó los pasos a seguir. El cliente agradeció la eficiencia del proceso.\n",
      "\n",
      "\n",
      "Resumen: El cliente, insatisfecho con la calidad del producto, agradecía la eficiencia del proceso\n",
      "Palabras clave: [('estaba insatisfecho', 0.8036), ('insatisfecho la', 0.7843), ('procesó la', 0.7764), ('cliente agradeció', 0.7515), ('del producto', 0.7513)]\n",
      "Entidades nombradas: [('El asesor procesó la solicitud', 'MISC'), ('El cliente agradeció', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 9:\n",
      "El asesor ayudó al cliente a resolver un problema técnico complejo con el software. La llamada duró más de lo esperado, pero el cliente quedó muy satisfecho con la solución y elogió la profesionalidad del asesor.\n",
      "\n",
      "\n",
      "Resumen: El asesor ayudó al cliente a resolver un problema técnico complejo con el software. El cliente quedó muy satisfecho con la solución\n",
      "Palabras clave: [('software la', 0.7531), ('el software', 0.7475), ('quedó muy', 0.7398), ('cliente quedó', 0.7291), ('al cliente', 0.7269)]\n",
      "Entidades nombradas: [('La llamada duró más de', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Conversación 10:\n",
      "El cliente tenía preguntas sobre los términos y condiciones del contrato. El asesor respondió a todas las preguntas con claridad y precisión, lo que llevó al cliente a sentirse más seguro y confiado en su decisión de continuar con el servicio.\n",
      "\n",
      "\n",
      "Resumen: El cliente tenía preguntas sobre los términos y condiciones del contrato. El cliente tiene preguntas sobre las palabras y condiciones de contrato\n",
      "Palabras clave: [('tenía preguntas', 0.7437), ('sobre los', 0.729), ('cliente tenía', 0.727), ('todas las', 0.7236), ('preguntas sobre', 0.7222)]\n",
      "Entidades nombradas: [('El asesor respondió', 'MISC')]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from keybert import KeyBERT\n",
    "import spacy\n",
    "\n",
    "# Datos de ejemplo (simulados)\n",
    "conversations = [\n",
    "    \"El cliente expresó claramente sus preocupaciones sobre el rendimiento del producto y el asesor pudo ofrecer soluciones efectivas. El cliente se mostró satisfecho con la atención recibida y elogió la rapidez de la respuesta.\",\n",
    "    \"La conversación fue confusa y el asesor no pudo ayudar al cliente de manera satisfactoria. El cliente quedó insatisfecho con la falta de soluciones ofrecidas y mencionó que considerará cambiar de proveedor.\",\n",
    "    \"El asesor mostró empatía y comprensión hacia las necesidades del cliente, ofreciendo varias opciones de solución y explicando cada una en detalle. El cliente valoró la paciencia y el conocimiento del asesor.\",\n",
    "    \"El cliente mencionó problemas recurrentes con el servicio, y aunque el asesor intentó ayudar, no se logró resolver la situación durante la llamada. El cliente expresó frustración y solicitó hablar con un supervisor.\",\n",
    "    \"El cliente estaba molesto por la falta de comunicación sobre el estado de su pedido. El asesor se disculpó y ofreció un descuento en la próxima compra como compensación. El cliente aceptó la oferta y agradeció la solución rápida.\",\n",
    "    \"El asesor proporcionó información detallada sobre las características del nuevo producto, respondiendo a todas las preguntas del cliente. El cliente expresó su interés en realizar una compra y pidió más detalles sobre el proceso de envío.\",\n",
    "    \"La llamada fue muy positiva, con el asesor y el cliente discutiendo posibles mejoras al servicio. El cliente ofreció sugerencias constructivas y el asesor se comprometió a transmitirlas al equipo correspondiente.\",\n",
    "    \"El cliente estaba insatisfecho con la calidad del producto recibido y solicitó un reembolso. El asesor procesó la solicitud de reembolso de inmediato y explicó los pasos a seguir. El cliente agradeció la eficiencia del proceso.\",\n",
    "    \"El asesor ayudó al cliente a resolver un problema técnico complejo con el software. La llamada duró más de lo esperado, pero el cliente quedó muy satisfecho con la solución y elogió la profesionalidad del asesor.\",\n",
    "    \"El cliente tenía preguntas sobre los términos y condiciones del contrato. El asesor respondió a todas las preguntas con claridad y precisión, lo que llevó al cliente a sentirse más seguro y confiado en su decisión de continuar con el servicio.\"\n",
    "]\n",
    "\n",
    "# Tokenizador y modelo BERT en español\n",
    "tokenizer = BertTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "encoded_inputs = tokenizer(conversations, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "# Intentar cargar el modelo de resumen en español\n",
    "try:\n",
    "    tokenizer_summarizer = AutoTokenizer.from_pretrained(\"mrm8488/bert2bert_shared-spanish-finetuned-summarization\")\n",
    "    model_summarizer = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/bert2bert_shared-spanish-finetuned-summarization\")\n",
    "except:\n",
    "    tokenizer_summarizer = AutoTokenizer.from_pretrained(\"mrm8488/mbart-large-cc25-summarizer\")\n",
    "    model_summarizer = AutoModelForSeq2SeqLM.from_pretrained(\"mrm8488/mbart-large-cc25-summarizer\")\n",
    "\n",
    "# Crear el pipeline de resumen\n",
    "summarizer = pipeline(\"summarization\", model=model_summarizer, tokenizer=tokenizer_summarizer)\n",
    "\n",
    "# Crear el modelo KeyBERT en español\n",
    "kw_model = KeyBERT('dccuchile/bert-base-spanish-wwm-cased')\n",
    "\n",
    "# Cargar el modelo de spaCy para español\n",
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "for i, conversation in enumerate(conversations):\n",
    "    print(f\"Conversación {i+1}:\")\n",
    "    print(conversation)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    # Resumir la conversación\n",
    "    input_length = len(conversation.split())\n",
    "    max_len = min(50, input_length)  # Ajustar max_length dinámicamente\n",
    "    summary = summarizer(conversation, max_length=max_len, min_length=max_len // 2, do_sample=False)\n",
    "    print(\"Resumen:\", summary[0]['summary_text'])\n",
    "    \n",
    "    # Extraer palabras clave\n",
    "    keywords = kw_model.extract_keywords(conversation, keyphrase_ngram_range=(1, 2), stop_words='spanish')\n",
    "    if not keywords:\n",
    "        keywords = kw_model.extract_keywords(conversation, keyphrase_ngram_range=(1, 2))\n",
    "    print(\"Palabras clave:\", keywords)\n",
    "    \n",
    "    # Identificar entidades nombradas\n",
    "    doc = nlp(conversation)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(\"Entidades nombradas:\", entities)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NPL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
